{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmarhafeez1/object_detection_yolov5/blob/main/Object_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRtYN_ps0FIw"
      },
      "outputs": [],
      "source": [
        "# Step 1: Set up the environment\n",
        "!pip install torch torchvision\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uyBtHA22tTG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqAspEeTWBtQ"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load the YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Set the classes we're interested in (person, car, and animal classes from COCO)\n",
        "model.classes = [0, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
        "\n",
        "# Set confidence threshold\n",
        "model.conf = 0.25  # NMS confidence threshold\n",
        "model.iou = 0.45   # NMS IoU threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMyG4zx_WFd7"
      },
      "outputs": [],
      "source": [
        "def getFrame(sec, quality=0.8):\n",
        "    # JavaScript to capture frame from webcam\n",
        "    js = Javascript('''\n",
        "        async function getFrame(sec, quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "            await new Promise(r => setTimeout(r, sec * 1000));\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            const result = canvas.toDataURL('image/jpeg', quality);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return result;\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('getFrame({}, {})'.format(sec, quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    return PIL.Image.open(io.BytesIO(binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xxum-M5kWH2F"
      },
      "outputs": [],
      "source": [
        "def processFrame(frame):\n",
        "    # Convert PIL Image to OpenCV format\n",
        "    open_cv_image = np.array(frame.convert('RGB'))\n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "\n",
        "    # Perform detection\n",
        "    results = model(open_cv_image)\n",
        "\n",
        "    # Process results\n",
        "    for det in results.xyxy[0]:  # det is (x1, y1, x2, y2, conf, cls)\n",
        "        x1, y1, x2, y2, conf, cls = det.tolist()\n",
        "        label = model.names[int(cls)]\n",
        "        color = (0, 255, 0) if label == 'person' else (0, 0, 255) if label == 'car' else (255, 0, 0)\n",
        "        cv2.rectangle(open_cv_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
        "        cv2.putText(open_cv_image, f'{label} {conf:.2f}', (int(x1), int(y1) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "    # Convert back to PIL Image\n",
        "    return PIL.Image.fromarray(open_cv_image[:, :, ::-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LCXhAMeMWMGO"
      },
      "outputs": [],
      "source": [
        "# Step 5: Main loop for capturing and processing frames\n",
        "def runDetection(duration=30, interval=1):\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < duration:\n",
        "        frame = getFrame(interval)\n",
        "        processed_frame = processFrame(frame)\n",
        "        display(processed_frame)\n",
        "\n",
        "# Step 6: Run the detection\n",
        "runDetection(duration=30, interval=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T7Z9daXWibs"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def upload_and_detect():\n",
        "    # Upload an image\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get the uploaded image\n",
        "    for filename in uploaded.keys():\n",
        "        # Read the image file\n",
        "        image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "        # Convert PIL Image to OpenCV format\n",
        "        open_cv_image = np.array(image.convert('RGB'))\n",
        "        open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "\n",
        "        # Perform detection\n",
        "        results = model(open_cv_image)\n",
        "\n",
        "        # Get the rendered image with detections from YOLOv5\n",
        "        rendered_image = results.render()[0]\n",
        "\n",
        "        # Convert back to RGB for displaying\n",
        "        rgb_image = cv2.cvtColor(rendered_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the result\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(rgb_image)\n",
        "        plt.axis('off')\n",
        "        plt.title('Detected Objects')\n",
        "        plt.show()\n",
        "\n",
        "        # Print detection summary\n",
        "        print(results.pandas().xyxy[0])\n",
        "\n",
        "# Run the function to upload and detect\n",
        "upload_and_detect()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOeTLaXboYxNKe2zD00aKmd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}